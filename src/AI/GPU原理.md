# GPU原理

### 为什么使用GPU来运行AI模型？

GPT的并行运算能力更强（矩阵运算），CPU的逻辑运算能力更强（if-else）

- 算力：能算多块
- 内存：能同时算多少

***



### 数据类型

==位数越高，需要的算力和内存越多，最终效果也越好==

| 数据类型 | 符号位（Sign） | Exponent（指数位） | Fraction（尾数位） | 分辨率 | 说明                                                         |
| -------- | -------------- | ------------------ | ------------------ | ------ | ------------------------------------------------------------ |
| FP64     | 1              | 11                 | 52                 |        | 双精度浮点数，IEEE 754                                       |
| FP32     | 1              | 8                  | 32                 |        | 单精度浮点数，IEEE 754                                       |
| FP16     | 1              | 5                  | 10                 |        | 半精度浮点数，IEEE 754                                       |
| TF32     | 1              | 8                  | 10                 |        | A100只后才支持，总共就19位，在性能、范围和精度上实现了平衡，只有 Ampere 架构以及之后的架构才支持 |
| BF16     | 1              | 8                  | 7                  | 0.001  | FP16的范围较小，容易溢出，BF16精度换范围，能有效防止溢出，但误差也会更大，谷歌开发，只有 Ampere 架构以及之后的架构才支持 |
| FP8 E4M3 | 1              | 4                  | 3                  |        |                                                              |
| FP8 E5M2 | 1              | 5                  | 2                  |        |                                                              |
| INT32    | 1              | 0                  | 31                 |        | 量化精度                                                     |
| INT16    | 1              | 0                  | 15                 |        | 量化精度                                                     |
| INT8     | 1              | 0                  | 7                  |        | 量化精度                                                     |
| INT4     | 1              | 0                  | 3                  |        | 量化精度                                                     |
| NF4      |                |                    |                    |        | 4-bit NormalFloat                                            |

***



### 计算指标

- FLOP/FLOPs：浮点运算量，用于表示需要多少算力

- OPS：1 OPS表示每秒1次运算，1 TOPS表示每秒1万亿次运算
- FLOPS：浮点运行，1 FLOPS表示每秒1次浮点运算，1 TFLOPS表示每秒1万亿次浮点运算
- MACs：乘加累计，约等于FLOPS的一半
- MAC：内存占用量

***



### GPU

| 性能参数              | V100         | A100/A800   | H100/H800    | H200 | B100/B200（2024.03） |
| --------------------- | ------------ | ----------- | ------------ | ---- | -------------------- |
| 微架构                | Volta        | Ampere      | Hopper       |      |                      |
| FP64                  | 7 TFLOPS     | 9.7 TFLOPS  | 26 TFLOPS    |      |                      |
| FP64 Tensor Core      |              | 19.5 TFLOPS |              |      |                      |
| FP32                  | 14 TFLOPS    | 19.5 TFLOPS | 51 TFLOPS    |      |                      |
| TF32                  |              | 156 TFLOPS  |              |      |                      |
| FP16 Tensor Core      |              | 312 TFLOPS  | 756.5 TFLOPS |      |                      |
| INT8 Tensor Core      | 62 TOPS      | 624 TOPS    | 1513 TOPS    |      |                      |
| GPU 显存              | 32/16GB HBM2 | 80GB HBM2e  | 80GB         |      |                      |
| GPU 显存带宽          | 900GB/s      | 1935GB/s    | 2TB/s        |      |                      |
| 最大热设计功耗（TDP） | 250 W        | 300 W       | 300-350 W    |      |                      |

- 计算性能

  - 计算精度

    | 数据类型 | 别名    | 解析               | 占用空间 | 场景                   |
    | -------- | ------- | ------------------ | -------- | ---------------------- |
    | INT8     | 8位整数 | -128 ~ 127         | 1字节    | 低性能的开发板         |
    | FP16     | 半精    | 精确到小数点后三位 | 2字节    | 小显存显卡或则精度场景 |
    | FP32     | 单精度  | 精确到小数点后六位 | 4字节    | 最常用的精度           |

  - FLOP/FLOPs（s是小写）：浮点运算

  - FLOPS（S是大写）：每秒浮点运算
  
  - TFLOPS：每秒一万亿次浮点运算
  
    www.techpowerup.com/gpu-specs

图形性能

[2024年最新：一文看懂英伟达显卡B100、H200、L40S、A100、A800、H100、H800、V100如何选择，附架构技术和性能对比 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/681156168)

[Llama-2 LLM各个版本GPU服务器的配置要求是什么？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/667446173)

### NVIDIA GPU 产品线

| 产品线            | 定位                       | 应用场景                                       | 代表型号                              |
| ----------------- | -------------------------- | ---------------------------------------------- | ------------------------------------- |
| GeForce           | 计算机的图形处理和游戏运行 | 消费者应用的中高端PC市场                       | GeForce RTX 4090、GeForce RTX 4080    |
| NVIDIA RTX/Quadro | 专业视觉计算平台           | 建筑设计、媒体与娱乐等行业专业用户的PC、工作站 | NVIDIA RTX A6000、Quadro GV100        |
| Data Center       | 数据中心加速计算平台       | AI、数据分析、高性能计算（HPC）                | NVIDIA H100、NVIDIA A100、NIVDIA V100 |

- GeForce GTX：早期图形显卡
- GeForce RTX：引入光线追踪，更好的核心

***



### Nvidia GPU 的核心架构及参数

- CUDA Core：CUDA Core 是 NVIDIA GPU上的计算核心单元，用于执行通用的并行计算任务，是最常看到的核心类型。NVIDIA 通常用最小的运算单元表示自己的运算能力，CUDA Core 指的是一个执行基础运算的处理元件，我们所说的 CUDA Core 数量，通常对应的是 FP32 计算单元的数量。
- Tensor Core：矩阵运算加速模块，是 Volta 架构及其后续架构中引入的一种特殊计算单元。它们专门用于深度学习任务中的张量计算，如矩阵乘法和卷积运算。Tensor Core 核心特别大，通常与深度学习框架（如 TensorFlow 和 PyTorch）相结合使用，它可以把整个矩阵都载入寄存器中批量运算，实现十几倍的效率提升。
- RT Core：RT Core 是 NVIDIA 的专用硬件单元，主要用于加速光线追踪计算。正常数据中心级的 GPU 核心是没有 RT Core 的，主要是消费级显卡才为光线追踪运算添加了 RTCores。RT Core 主要用于游戏开发、电影制作和虚拟现实等需要实时渲染的领域。

架构

- Volta：Volta 架构是 NVIDIA GPU 的第六代架构，发布于 2017 年。Volta 架构专注于深度学习和人工智能应用，并引入了 Tensor Core。
- Turing：Turing 架构是 NVIDIA GPU 的第七代架构，发布于 2018 年。Turing 架构引入了实时光线追踪（RTX）和深度学习超采样（DLSS）等重要功能。
- Ampere：Ampere 架构是 NVIDIA GPU 的第八代架构，2020 年发布。Ampere 架构在计算能力、能效和深度学习性能方面都有重大提升。Ampere 架构的 GPU 采用了多个[流多处理器]（SM）和更大的总线宽度，提供了更多的 CUDA Core 和更高的频率。它还引入了第三代 Tensor Core，提供更强大的深度学习计算性能。Ampere 架构的 GPU 还具有更高的内存容量和带宽，适用于大规模的数据处理和机器学习任务。
- Hopper：Hopper 架构是 NVIDIA GPU 的第九代架构，2022 年发布。相较于 Ampere，Hopper 架构支持第四代 Tensor Core，且采用新型流式处理器，每个 SM 能力更强。Hopper 架构在计算能力、深度学习加速和图形功能方面带来新的创新和改进。





### GPU工具

```shell
$ nvidia-smi
```

